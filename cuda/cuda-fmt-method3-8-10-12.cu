extern __shared__ double shared[];

// automatically generated by gen_fmt_method3 function
// m = 0, nexp = 10, eps = 1.0e-12
__device__ void gpu_fmt0_method3( const double t, const double coef, double fmt[] ) {
    //int it;
    //double t0, dt, *f, expt0, t2, ff[10];
    if ( t >= 26 ) {
        fmt[0] = coef * LDG(FMT_m_sqrt_pi_2) * sqrt(1.e0/t);
    } else {
      int it;
      double t0, dt, *f, expt0, t2;
      double delta = LDG(FMT_m_delta[0]);
      double dhalf = delta * 0.5;
        it = (int)(t*2);
        t0 = delta * (double)it + dhalf;
        t2 = t0 + t0;
        dt = t0 - t;
#ifndef CUDA_FMT_M_SM
        f  = &FMT_m_table0[it*2];
#else
        f  = (double *)&shared[it*2];
#endif
#if 1
        double ff[10];
        ff[10-1] = LDM(f[0]);
        expt0       = LDM(f[1]);
        // F(m+k)(T0) (k=0, n-2)
        ff[8] = LDG(FMT_m_dinv2[0+8]) * ( expt0 + t2*ff[9] );
        ff[7] = LDG(FMT_m_dinv2[0+7]) * ( expt0 + t2*ff[8] );
        ff[6] = LDG(FMT_m_dinv2[0+6]) * ( expt0 + t2*ff[7] );
        ff[5] = LDG(FMT_m_dinv2[0+5]) * ( expt0 + t2*ff[6] );
        ff[4] = LDG(FMT_m_dinv2[0+4]) * ( expt0 + t2*ff[5] );
        ff[3] = LDG(FMT_m_dinv2[0+3]) * ( expt0 + t2*ff[4] );
        ff[2] = LDG(FMT_m_dinv2[0+2]) * ( expt0 + t2*ff[3] );
        ff[1] = LDG(FMT_m_dinv2[0+1]) * ( expt0 + t2*ff[2] );
        ff[0] = LDG(FMT_m_dinv2[0+0]) * ( expt0 + t2*ff[1] );
        // F[0]
        fmt[0] = ff[0] + dt*( ff[1] + LDG(FMT_m_dinv[2])*dt*( ff[2] + LDG(FMT_m_dinv[3])*dt*
                ( ff[3] + LDG(FMT_m_dinv[4])*dt*( ff[4] + LDG(FMT_m_dinv[5])*dt*
                ( ff[5] + LDG(FMT_m_dinv[6])*dt*( ff[6] + LDG(FMT_m_dinv[7])*dt*
                ( ff[7] + LDG(FMT_m_dinv[8])*dt*( ff[8] + LDG(FMT_m_dinv[9])*dt*ff[9]))))))));
        fmt[0] *= coef;
#else
        double ff;
        ff = LDM(f[0]);
        expt0       = LDM(f[1]);
        // F(m+k)(T0) (k=0, n-2)
        // F[0]
        t0 = LDG(FMT_m_dinv[9])*dt*ff;
        ff = LDG(FMT_m_dinv2[0+8]) * ( expt0 + t2*ff );
        t0 = LDG(FMT_m_dinv[8])*dt*(ff + t0);
        ff = LDG(FMT_m_dinv2[0+7]) * ( expt0 + t2*ff );
        t0 = LDG(FMT_m_dinv[7])*dt*(ff + t0);
        ff = LDG(FMT_m_dinv2[0+6]) * ( expt0 + t2*ff );
        t0 = LDG(FMT_m_dinv[6])*dt*(ff + t0);
        ff = LDG(FMT_m_dinv2[0+5]) * ( expt0 + t2*ff );
        t0 = LDG(FMT_m_dinv[5])*dt*(ff + t0);
        ff = LDG(FMT_m_dinv2[0+4]) * ( expt0 + t2*ff );
        t0 = LDG(FMT_m_dinv[4])*dt*(ff + t0);
        ff = LDG(FMT_m_dinv2[0+3]) * ( expt0 + t2*ff );
        t0 = LDG(FMT_m_dinv[3])*dt*(ff + t0);
        ff = LDG(FMT_m_dinv2[0+2]) * ( expt0 + t2*ff );
        t0 = LDG(FMT_m_dinv[2])*dt*(ff + t0);
        ff = LDG(FMT_m_dinv2[0+1]) * ( expt0 + t2*ff ); // ff[1]
        t0 = dt*(ff + t0);
        ff = LDG(FMT_m_dinv2[0+0]) * ( expt0 + t2*ff ); // ff[0]
        fmt[0] = coef * (ff + t0);
#endif
    }
}

// automatically generated by gen_fmt_method3 function
// m = 1, nexp = 10, eps = 1.0e-12
__device__ void gpu_fmt1_method3( const double t, const double coef, double fmt[] ) {
    int it;
    double t0, dt, *f, expt0, t2, ff[10], sqrt2, dtk[11], expt;
    if ( t >= 30 ) {
        sqrt2  = sqrt( 0.5e0 / t );
        t2     = sqrt2*sqrt2;
        fmt[0] = coef * LDG(FMT_m_sqrt_pi2) * sqrt2;
        fmt[1] =        t2 * fmt[0];
    } else {
      double delta = LDG(FMT_m_delta[1]);
      double dhalf = delta * 0.5;
        it = (int)(t*2);
        t0 = delta * (double)it + dhalf;
        t2 = t0 + t0;
        dt = t0 - t;
#ifndef CUDA_FMT_M_SM
        f  = &FMT_m_table1[it*2];
#else
        f  = (double *)&shared[it*2];
#endif
        expt0       = LDM(f[1]);
        // (-dt)^k/k!
        dtk[1] = dt;
        for (int k=2; k<11; k++ ) dtk[k] = dt*LDG(FMT_m_dinv[k])*dtk[k-1];
        // exp(-T)
        expt = 1.e0 + dtk[1] + dtk[2] + dtk[3] + dtk[4] + dtk[5] + dtk[6]
                 + dtk[7] + dtk[8] + dtk[9] + dtk[10];
        expt *= expt0;
#if 0
        ff[10-1] = LDM(f[0]);
        // F(m+k)(T0) (k=0, n-2)
        ff[8] = LDG(FMT_m_dinv2[1+8]) * ( expt0 + t2*ff[9] );
        ff[7] = LDG(FMT_m_dinv2[1+7]) * ( expt0 + t2*ff[8] );
        ff[6] = LDG(FMT_m_dinv2[1+6]) * ( expt0 + t2*ff[7] );
        ff[5] = LDG(FMT_m_dinv2[1+5]) * ( expt0 + t2*ff[6] );
        ff[4] = LDG(FMT_m_dinv2[1+4]) * ( expt0 + t2*ff[5] );
        ff[3] = LDG(FMT_m_dinv2[1+3]) * ( expt0 + t2*ff[4] );
        ff[2] = LDG(FMT_m_dinv2[1+2]) * ( expt0 + t2*ff[3] );
        ff[1] = LDG(FMT_m_dinv2[1+1]) * ( expt0 + t2*ff[2] );
        ff[0] = LDG(FMT_m_dinv2[1+0]) * ( expt0 + t2*ff[1] );
        // F[1]
        fmt[1] = ff[0] + dtk[1]*ff[1] + dtk[2]*ff[2] + dtk[3]*ff[3]
                 + dtk[4]*ff[4] + dtk[5]*ff[5] + dtk[6]*ff[6]
                 + dtk[7]*ff[7] + dtk[8]*ff[8] + dtk[9]*ff[9];
#else
        double ff0 = LDM(f[0]);
        fmt[1] = dtk[9]*ff0;
        // F(m+k)(T0) (k=0, n-2)
        for (int k=8,i=0; i<8; i++,k--) {
          ff0 = LDG(FMT_m_dinv2[1+k]) * ( expt0 + t2*ff0 );
          fmt[1] += dtk[k] * ff0;
        }
        fmt[1] += LDG(FMT_m_dinv2[1+0]) * ( expt0 + t2*ff0 );
#endif
        fmt[1] *= coef;
        // F[0]-F[0]
        t2 = t + t;
        fmt[0] = coef*expt + t2*fmt[1];
    }
}

// automatically generated by gen_fmt_method3 function
// m = 2, nexp = 10, eps = 1.0e-12
__device__ void gpu_fmt2_method3( const double t, const double coef, double fmt[] ) {
    int it, k;
    double t0, dt, *f, expt0, t2, ff[10], sqrt2, dtk[11], expt;
    if ( t >= 33 ) {
        sqrt2  = sqrt( 0.5e0 / t );
        t2     = sqrt2*sqrt2;
        fmt[0] = coef * LDG(FMT_m_sqrt_pi2) * sqrt2;
        fmt[1] =        t2 * fmt[0];
        fmt[2] = 3.e0 * t2 * fmt[1];
    } else {
      double delta = LDG(FMT_m_delta[2]);
      double dhalf = delta * 0.5;
        it = (int)(t*2);
        t0 = delta * (double)it + dhalf;
        t2 = t0 + t0;
        dt = t0 - t;
#ifndef CUDA_FMT_M_SM
        f  = &FMT_m_table2[it*2];
#else
        f  = (double *)&shared[it*2];
#endif
        ff[10-1] = LDM(f[0]);
        expt0       = LDM(f[1]);
        // (-dt)^k/k!
        dtk[1] = dt;
        for ( k=2; k<11; k++ ) dtk[k] = dt*LDG(FMT_m_dinv[k])*dtk[k-1];
        // exp(-T)
        expt = 1.e0 + dtk[1] + dtk[2] + dtk[3] + dtk[4] + dtk[5] + dtk[6]
                 + dtk[7] + dtk[8] + dtk[9] + dtk[10];
        expt *= expt0;
        // F(m+k)(T0) (k=0, n-2)
        ff[8] = LDG(FMT_m_dinv2[2+8]) * ( expt0 + t2*ff[9] );
        ff[7] = LDG(FMT_m_dinv2[2+7]) * ( expt0 + t2*ff[8] );
        ff[6] = LDG(FMT_m_dinv2[2+6]) * ( expt0 + t2*ff[7] );
        ff[5] = LDG(FMT_m_dinv2[2+5]) * ( expt0 + t2*ff[6] );
        ff[4] = LDG(FMT_m_dinv2[2+4]) * ( expt0 + t2*ff[5] );
        ff[3] = LDG(FMT_m_dinv2[2+3]) * ( expt0 + t2*ff[4] );
        ff[2] = LDG(FMT_m_dinv2[2+2]) * ( expt0 + t2*ff[3] );
        ff[1] = LDG(FMT_m_dinv2[2+1]) * ( expt0 + t2*ff[2] );
        ff[0] = LDG(FMT_m_dinv2[2+0]) * ( expt0 + t2*ff[1] );
        // F[2]
        fmt[2] = ff[0] + dtk[1]*ff[1] + dtk[2]*ff[2] + dtk[3]*ff[3]
                 + dtk[4]*ff[4] + dtk[5]*ff[5] + dtk[6]*ff[6]
                 + dtk[7]*ff[7] + dtk[8]*ff[8] + dtk[9]*ff[9];
        fmt[2] *= coef;
        // F[1]-F[0]
        t2 = t + t;
        expt      *= coef;
        fmt[1] = LDG(FMT_m_dinv2[1]) * ( expt + t2 * fmt[2] );
        fmt[0] =              expt + t2 * fmt[1];
    }
}

// automatically generated by gen_fmt_method3 function
// m = 3, nexp = 10, eps = 1.0e-12
__device__ void gpu_fmt3_method3( const double t, const double coef, double fmt[] ) {
    int it, k;
    double t0, dt, *f, expt0, t2, ff[10], sqrt2, dtk[11], expt;
    if ( t >= 36 ) {
        sqrt2  = sqrt( 0.5e0 / t );
        t2     = sqrt2*sqrt2;
        fmt[0] = coef * LDG(FMT_m_sqrt_pi2) * sqrt2;
        fmt[1] =        t2 * fmt[0];
        fmt[2] = 3.e0 * t2 * fmt[1];
        fmt[3] = 5.e0 * t2 * fmt[2];
    } else {
      double delta = LDG(FMT_m_delta[3]);
      double dhalf = delta * 0.5;
        it = (int)(t*2);
        t0 = delta * (double)it + dhalf;
        t2 = t0 + t0;
        dt = t0 - t;
#ifndef CUDA_FMT_M_SM
        f  = &FMT_m_table3[it*2];
#else
        f  = (double *)&shared[it*2];
#endif
        ff[10-1] = LDM(f[0]);
        expt0       = LDM(f[1]);
        // (-dt)^k/k!
        dtk[1] = dt;
        for ( k=2; k<11; k++ ) dtk[k] = dt*LDG(FMT_m_dinv[k])*dtk[k-1];
        // exp(-T)
        expt = 1.e0 + dtk[1] + dtk[2] + dtk[3] + dtk[4] + dtk[5] + dtk[6]
                 + dtk[7] + dtk[8] + dtk[9] + dtk[10];
        expt *= expt0;
        // F(m+k)(T0) (k=0, n-2)
        ff[8] = LDG(FMT_m_dinv2[3+8]) * ( expt0 + t2*ff[9] );
        ff[7] = LDG(FMT_m_dinv2[3+7]) * ( expt0 + t2*ff[8] );
        ff[6] = LDG(FMT_m_dinv2[3+6]) * ( expt0 + t2*ff[7] );
        ff[5] = LDG(FMT_m_dinv2[3+5]) * ( expt0 + t2*ff[6] );
        ff[4] = LDG(FMT_m_dinv2[3+4]) * ( expt0 + t2*ff[5] );
        ff[3] = LDG(FMT_m_dinv2[3+3]) * ( expt0 + t2*ff[4] );
        ff[2] = LDG(FMT_m_dinv2[3+2]) * ( expt0 + t2*ff[3] );
        ff[1] = LDG(FMT_m_dinv2[3+1]) * ( expt0 + t2*ff[2] );
        ff[0] = LDG(FMT_m_dinv2[3+0]) * ( expt0 + t2*ff[1] );
        // F[3]
        fmt[3] = ff[0] + dtk[1]*ff[1] + dtk[2]*ff[2] + dtk[3]*ff[3]
                 + dtk[4]*ff[4] + dtk[5]*ff[5] + dtk[6]*ff[6]
                 + dtk[7]*ff[7] + dtk[8]*ff[8] + dtk[9]*ff[9];
        fmt[3] *= coef;
        // F[2]-F[0]
        t2 = t + t;
        expt      *= coef;
        fmt[2] = LDG(FMT_m_dinv2[2]) * ( expt + t2 * fmt[3] );
        fmt[1] = LDG(FMT_m_dinv2[1]) * ( expt + t2 * fmt[2] );
        fmt[0] =              expt + t2 * fmt[1];
    }
}

// automatically generated by gen_fmt_method3 function
// m = 4, nexp = 10, eps = 1.0e-12
__device__ void gpu_fmt4_method3( const double t, const double coef, double fmt[] ) {
    int it, k;
    double t0, dt, *f, expt0, t2, ff[10], sqrt2, dtk[11], expt;
    if ( t >= 39 ) {
        sqrt2  = sqrt( 0.5e0 / t );
        t2     = sqrt2*sqrt2;
        fmt[0] = coef * LDG(FMT_m_sqrt_pi2) * sqrt2;
        fmt[1] =        t2 * fmt[0];
        fmt[2] = 3.e0 * t2 * fmt[1];
        fmt[3] = 5.e0 * t2 * fmt[2];
        fmt[4] = 7.e0 * t2 * fmt[3];
    } else {
      double delta = LDG(FMT_m_delta[4]);
      double dhalf = delta * 0.5;
        it = (int)(t*2);
        t0 = delta * (double)it + dhalf;
        t2 = t0 + t0;
        dt = t0 - t;
#ifndef CUDA_FMT_M_SM
        f  = &FMT_m_table4[it*2];
#else
        f  = (double *)&shared[it*2];
#endif
        ff[10-1] = LDM(f[0]);
        expt0       = LDM(f[1]);
        // (-dt)^k/k!
        dtk[1] = dt;
        for ( k=2; k<11; k++ ) dtk[k] = dt*LDG(FMT_m_dinv[k])*dtk[k-1];
        // exp(-T)
        expt = 1.e0 + dtk[1] + dtk[2] + dtk[3] + dtk[4] + dtk[5] + dtk[6]
                 + dtk[7] + dtk[8] + dtk[9] + dtk[10];
        expt *= expt0;
        // F(m+k)(T0) (k=0, n-2)
        ff[8] = LDG(FMT_m_dinv2[4+8]) * ( expt0 + t2*ff[9] );
        ff[7] = LDG(FMT_m_dinv2[4+7]) * ( expt0 + t2*ff[8] );
        ff[6] = LDG(FMT_m_dinv2[4+6]) * ( expt0 + t2*ff[7] );
        ff[5] = LDG(FMT_m_dinv2[4+5]) * ( expt0 + t2*ff[6] );
        ff[4] = LDG(FMT_m_dinv2[4+4]) * ( expt0 + t2*ff[5] );
        ff[3] = LDG(FMT_m_dinv2[4+3]) * ( expt0 + t2*ff[4] );
        ff[2] = LDG(FMT_m_dinv2[4+2]) * ( expt0 + t2*ff[3] );
        ff[1] = LDG(FMT_m_dinv2[4+1]) * ( expt0 + t2*ff[2] );
        ff[0] = LDG(FMT_m_dinv2[4+0]) * ( expt0 + t2*ff[1] );
        // F[4]
        fmt[4] = ff[0] + dtk[1]*ff[1] + dtk[2]*ff[2] + dtk[3]*ff[3]
                 + dtk[4]*ff[4] + dtk[5]*ff[5] + dtk[6]*ff[6]
                 + dtk[7]*ff[7] + dtk[8]*ff[8] + dtk[9]*ff[9];
        fmt[4] *= coef;
        // F[3]-F[0]
        t2 = t + t;
        expt      *= coef;
        fmt[3] = LDG(FMT_m_dinv2[3]) * ( expt + t2 * fmt[4] );
        fmt[2] = LDG(FMT_m_dinv2[2]) * ( expt + t2 * fmt[3] );
        fmt[1] = LDG(FMT_m_dinv2[1]) * ( expt + t2 * fmt[2] );
        fmt[0] =              expt + t2 * fmt[1];
    }
}

// automatically generated by gen_fmt_method3 function
// m = 5, nexp = 10, eps = 1.0e-12
__device__ void gpu_fmt5_method3( const double t, const double coef, double fmt[] ) {
    int it, k;
    double t0, dt, *f, expt0, t2, ff[10], sqrt2, dtk[11], expt;
    if ( t >= 41 ) {
        sqrt2  = sqrt( 0.5e0 / t );
        t2     = sqrt2*sqrt2;
        fmt[0] = coef * LDG(FMT_m_sqrt_pi2) * sqrt2;
        fmt[1] =         t2 * fmt[0];
        fmt[2] =  3.e0 * t2 * fmt[1];
        fmt[3] =  5.e0 * t2 * fmt[2];
        fmt[4] =  7.e0 * t2 * fmt[3];
        fmt[5] =  9.e0 * t2 * fmt[4];
    } else {
      double delta = LDG(FMT_m_delta[5]);
      double dhalf = delta * 0.5;
        it = (int)(t*2);
        t0 = delta * (double)it + dhalf;
        t2 = t0 + t0;
        dt = t0 - t;
#ifndef CUDA_FMT_M_SM
        f  = &FMT_m_table5[it*2];
#else
        f  = (double *)&shared[it*2];
#endif
        ff[10-1] = LDM(f[0]);
        expt0       = LDM(f[1]);
        // (-dt)^k/k!
        dtk[1] = dt;
        for ( k=2; k<11; k++ ) dtk[k] = dt*LDG(FMT_m_dinv[k])*dtk[k-1];
        // exp(-T)
        expt = 1.e0 + dtk[1] + dtk[2] + dtk[3] + dtk[4] + dtk[5] + dtk[6]
                 + dtk[7] + dtk[8] + dtk[9] + dtk[10];
        expt *= expt0;
        // F(m+k)(T0) (k=0, n-2)
        ff[8] = LDG(FMT_m_dinv2[5+8]) * ( expt0 + t2*ff[9] );
        ff[7] = LDG(FMT_m_dinv2[5+7]) * ( expt0 + t2*ff[8] );
        ff[6] = LDG(FMT_m_dinv2[5+6]) * ( expt0 + t2*ff[7] );
        ff[5] = LDG(FMT_m_dinv2[5+5]) * ( expt0 + t2*ff[6] );
        ff[4] = LDG(FMT_m_dinv2[5+4]) * ( expt0 + t2*ff[5] );
        ff[3] = LDG(FMT_m_dinv2[5+3]) * ( expt0 + t2*ff[4] );
        ff[2] = LDG(FMT_m_dinv2[5+2]) * ( expt0 + t2*ff[3] );
        ff[1] = LDG(FMT_m_dinv2[5+1]) * ( expt0 + t2*ff[2] );
        ff[0] = LDG(FMT_m_dinv2[5+0]) * ( expt0 + t2*ff[1] );
        // F[5]
        fmt[5] = ff[0] + dtk[1]*ff[1] + dtk[2]*ff[2] + dtk[3]*ff[3]
                 + dtk[4]*ff[4] + dtk[5]*ff[5] + dtk[6]*ff[6]
                 + dtk[7]*ff[7] + dtk[8]*ff[8] + dtk[9]*ff[9];
        fmt[5] *= coef;
        // F[4]-F[0]
        t2 = t + t;
        expt      *= coef;
        fmt[4] = LDG(FMT_m_dinv2[4]) * ( expt + t2 * fmt[5] );
        fmt[3] = LDG(FMT_m_dinv2[3]) * ( expt + t2 * fmt[4] );
        fmt[2] = LDG(FMT_m_dinv2[2]) * ( expt + t2 * fmt[3] );
        fmt[1] = LDG(FMT_m_dinv2[1]) * ( expt + t2 * fmt[2] );
        fmt[0] =              expt + t2 * fmt[1];
    }
}

// automatically generated by gen_fmt_method3 function
// m = 6, nexp = 10, eps = 1.0e-12
__device__ void gpu_fmt6_method3( const double t, const double coef, double fmt[] ) {
    int it, k;
    double t0, dt, *f, expt0, t2, ff[10], sqrt2, dtk[11], expt;
    if ( t >= 43 ) {
        sqrt2  = sqrt( 0.5e0 / t );
        t2     = sqrt2*sqrt2;
        fmt[0] = coef * LDG(FMT_m_sqrt_pi2) * sqrt2;
        fmt[1] =         t2 * fmt[0];
        fmt[2] =  3.e0 * t2 * fmt[1];
        fmt[3] =  5.e0 * t2 * fmt[2];
        fmt[4] =  7.e0 * t2 * fmt[3];
        fmt[5] =  9.e0 * t2 * fmt[4];
        fmt[6] = 11.e0 * t2 * fmt[5];
    } else {
      double delta = LDG(FMT_m_delta[6]);
      double dhalf = delta * 0.5;
        it = (int)(t*2);
        t0 = delta * (double)it + dhalf;
        t2 = t0 + t0;
        dt = t0 - t;
#ifndef CUDA_FMT_M_SM
        f  = &FMT_m_table6[it*2];
#else
        f  = (double *)&shared[it*2];
#endif
        ff[10-1] = LDM(f[0]);
        expt0       = LDM(f[1]);
        // (-dt)^k/k!
        dtk[1] = dt;
        for ( k=2; k<11; k++ ) dtk[k] = dt*LDG(FMT_m_dinv[k])*dtk[k-1];
        // exp(-T)
        expt = 1.e0 + dtk[1] + dtk[2] + dtk[3] + dtk[4] + dtk[5] + dtk[6]
                 + dtk[7] + dtk[8] + dtk[9] + dtk[10];
        expt *= expt0;
        // F(m+k)(T0) (k=0, n-2)
        ff[8] = LDG(FMT_m_dinv2[6+8]) * ( expt0 + t2*ff[9] );
        ff[7] = LDG(FMT_m_dinv2[6+7]) * ( expt0 + t2*ff[8] );
        ff[6] = LDG(FMT_m_dinv2[6+6]) * ( expt0 + t2*ff[7] );
        ff[5] = LDG(FMT_m_dinv2[6+5]) * ( expt0 + t2*ff[6] );
        ff[4] = LDG(FMT_m_dinv2[6+4]) * ( expt0 + t2*ff[5] );
        ff[3] = LDG(FMT_m_dinv2[6+3]) * ( expt0 + t2*ff[4] );
        ff[2] = LDG(FMT_m_dinv2[6+2]) * ( expt0 + t2*ff[3] );
        ff[1] = LDG(FMT_m_dinv2[6+1]) * ( expt0 + t2*ff[2] );
        ff[0] = LDG(FMT_m_dinv2[6+0]) * ( expt0 + t2*ff[1] );
        // F[6]
        fmt[6] = ff[0] + dtk[1]*ff[1] + dtk[2]*ff[2] + dtk[3]*ff[3]
                 + dtk[4]*ff[4] + dtk[5]*ff[5] + dtk[6]*ff[6]
                 + dtk[7]*ff[7] + dtk[8]*ff[8] + dtk[9]*ff[9];
        fmt[6] *= coef;
        // F[5]-F[0]
        t2 = t + t;
        expt      *= coef;
        fmt[5] = LDG(FMT_m_dinv2[5]) * ( expt + t2 * fmt[6] );
        fmt[4] = LDG(FMT_m_dinv2[4]) * ( expt + t2 * fmt[5] );
        fmt[3] = LDG(FMT_m_dinv2[3]) * ( expt + t2 * fmt[4] );
        fmt[2] = LDG(FMT_m_dinv2[2]) * ( expt + t2 * fmt[3] );
        fmt[1] = LDG(FMT_m_dinv2[1]) * ( expt + t2 * fmt[2] );
        fmt[0] =              expt + t2 * fmt[1];
    }
}

// automatically generated by gen_fmt_method3 function
// m = 7, nexp = 10, eps = 1.0e-12
__device__ void gpu_fmt7_method3( const double t, const double coef, double fmt[] ) {
    int it, k;
    double t0, dt, *f, expt0, t2, ff[10], sqrt2, dtk[11], expt;
    if ( t >= 45 ) {
        sqrt2  = sqrt( 0.5e0 / t );
        t2     = sqrt2*sqrt2;
        fmt[0] = coef * LDG(FMT_m_sqrt_pi2) * sqrt2;
        fmt[1] =         t2 * fmt[0];
        fmt[2] =  3.e0 * t2 * fmt[1];
        fmt[3] =  5.e0 * t2 * fmt[2];
        fmt[4] =  7.e0 * t2 * fmt[3];
        fmt[5] =  9.e0 * t2 * fmt[4];
        fmt[6] = 11.e0 * t2 * fmt[5];
        fmt[7] = 13.e0 * t2 * fmt[6];
    } else {
      double delta = LDG(FMT_m_delta[7]);
      double dhalf = delta * 0.5;
        it = (int)(t*2);
        t0 = delta * (double)it + dhalf;
        t2 = t0 + t0;
        dt = t0 - t;
#ifndef CUDA_FMT_M_SM
        f  = &FMT_m_table7[it*2];
#else
        f  = (double *)&shared[it*2];
#endif
        ff[10-1] = LDM(f[0]);
        expt0       = LDM(f[1]);
        // (-dt)^k/k!
        dtk[1] = dt;
        for ( k=2; k<11; k++ ) dtk[k] = dt*LDG(FMT_m_dinv[k])*dtk[k-1];
        // exp(-T)
        expt = 1.e0 + dtk[1] + dtk[2] + dtk[3] + dtk[4] + dtk[5] + dtk[6]
                 + dtk[7] + dtk[8] + dtk[9] + dtk[10];
        expt *= expt0;
        // F(m+k)(T0) (k=0, n-2)
        ff[8] = LDG(FMT_m_dinv2[7+8]) * ( expt0 + t2*ff[9] );
        ff[7] = LDG(FMT_m_dinv2[7+7]) * ( expt0 + t2*ff[8] );
        ff[6] = LDG(FMT_m_dinv2[7+6]) * ( expt0 + t2*ff[7] );
        ff[5] = LDG(FMT_m_dinv2[7+5]) * ( expt0 + t2*ff[6] );
        ff[4] = LDG(FMT_m_dinv2[7+4]) * ( expt0 + t2*ff[5] );
        ff[3] = LDG(FMT_m_dinv2[7+3]) * ( expt0 + t2*ff[4] );
        ff[2] = LDG(FMT_m_dinv2[7+2]) * ( expt0 + t2*ff[3] );
        ff[1] = LDG(FMT_m_dinv2[7+1]) * ( expt0 + t2*ff[2] );
        ff[0] = LDG(FMT_m_dinv2[7+0]) * ( expt0 + t2*ff[1] );
        // F[7]
        fmt[7] = ff[0] + dtk[1]*ff[1] + dtk[2]*ff[2] + dtk[3]*ff[3]
                 + dtk[4]*ff[4] + dtk[5]*ff[5] + dtk[6]*ff[6]
                 + dtk[7]*ff[7] + dtk[8]*ff[8] + dtk[9]*ff[9];
        fmt[7] *= coef;
        // F[6]-F[0]
        t2 = t + t;
        expt      *= coef;
        fmt[6] = LDG(FMT_m_dinv2[6]) * ( expt + t2 * fmt[7] );
        fmt[5] = LDG(FMT_m_dinv2[5]) * ( expt + t2 * fmt[6] );
        fmt[4] = LDG(FMT_m_dinv2[4]) * ( expt + t2 * fmt[5] );
        fmt[3] = LDG(FMT_m_dinv2[3]) * ( expt + t2 * fmt[4] );
        fmt[2] = LDG(FMT_m_dinv2[2]) * ( expt + t2 * fmt[3] );
        fmt[1] = LDG(FMT_m_dinv2[1]) * ( expt + t2 * fmt[2] );
        fmt[0] =              expt + t2 * fmt[1];
    }
}

// automatically generated by gen_fmt_method3 function
// m = 8, nexp = 10, eps = 1.0e-12
__device__ void gpu_fmt8_method3( const double t, const double coef, double fmt[] ) {
    int it, k;
    double t0, dt, *f, expt0, t2, ff[10], sqrt2, dtk[11], expt;
    if ( t >= 48 ) {
        sqrt2  = sqrt( 0.5e0 / t );
        t2     = sqrt2*sqrt2;
        fmt[0] = coef * LDG(FMT_m_sqrt_pi2) * sqrt2;
        fmt[1] =         t2 * fmt[0];
        fmt[2] =  3.e0 * t2 * fmt[1];
        fmt[3] =  5.e0 * t2 * fmt[2];
        fmt[4] =  7.e0 * t2 * fmt[3];
        fmt[5] =  9.e0 * t2 * fmt[4];
        fmt[6] = 11.e0 * t2 * fmt[5];
        fmt[7] = 13.e0 * t2 * fmt[6];
        fmt[8] = 15.e0 * t2 * fmt[7];
    } else {
      double delta = LDG(FMT_m_delta[8]);
      double dhalf = delta * 0.5;
        it = (int)(t*2);
        t0 = delta * (double)it + dhalf;
        t2 = t0 + t0;
        dt = t0 - t;
#ifndef CUDA_FMT_M_SM
        f  = &FMT_m_table8[it*2];
#else
        f  = (double *)&shared[it*2];
#endif
        ff[10-1] = LDM(f[0]);
        expt0       = LDM(f[1]);
        // (-dt)^k/k!
        dtk[1] = dt;
        for ( k=2; k<11; k++ ) dtk[k] = dt*LDG(FMT_m_dinv[k])*dtk[k-1];
        // exp(-T)
        expt = 1.e0 + dtk[1] + dtk[2] + dtk[3] + dtk[4] + dtk[5] + dtk[6]
                 + dtk[7] + dtk[8] + dtk[9] + dtk[10];
        expt *= expt0;
        // F(m+k)(T0) (k=0, n-2)
        ff[8] = LDG(FMT_m_dinv2[8+8]) * ( expt0 + t2*ff[9] );
        ff[7] = LDG(FMT_m_dinv2[8+7]) * ( expt0 + t2*ff[8] );
        ff[6] = LDG(FMT_m_dinv2[8+6]) * ( expt0 + t2*ff[7] );
        ff[5] = LDG(FMT_m_dinv2[8+5]) * ( expt0 + t2*ff[6] );
        ff[4] = LDG(FMT_m_dinv2[8+4]) * ( expt0 + t2*ff[5] );
        ff[3] = LDG(FMT_m_dinv2[8+3]) * ( expt0 + t2*ff[4] );
        ff[2] = LDG(FMT_m_dinv2[8+2]) * ( expt0 + t2*ff[3] );
        ff[1] = LDG(FMT_m_dinv2[8+1]) * ( expt0 + t2*ff[2] );
        ff[0] = LDG(FMT_m_dinv2[8+0]) * ( expt0 + t2*ff[1] );
        // F[8]
        fmt[8] = ff[0] + dtk[1]*ff[1] + dtk[2]*ff[2] + dtk[3]*ff[3]
                 + dtk[4]*ff[4] + dtk[5]*ff[5] + dtk[6]*ff[6]
                 + dtk[7]*ff[7] + dtk[8]*ff[8] + dtk[9]*ff[9];
        fmt[8] *= coef;
        // F[7]-F[0]
        t2 = t + t;
        expt      *= coef;
        fmt[7] = LDG(FMT_m_dinv2[7]) * ( expt + t2 * fmt[8] );
        fmt[6] = LDG(FMT_m_dinv2[6]) * ( expt + t2 * fmt[7] );
        fmt[5] = LDG(FMT_m_dinv2[5]) * ( expt + t2 * fmt[6] );
        fmt[4] = LDG(FMT_m_dinv2[4]) * ( expt + t2 * fmt[5] );
        fmt[3] = LDG(FMT_m_dinv2[3]) * ( expt + t2 * fmt[4] );
        fmt[2] = LDG(FMT_m_dinv2[2]) * ( expt + t2 * fmt[3] );
        fmt[1] = LDG(FMT_m_dinv2[1]) * ( expt + t2 * fmt[2] );
        fmt[0] =              expt + t2 * fmt[1];
    }
}
